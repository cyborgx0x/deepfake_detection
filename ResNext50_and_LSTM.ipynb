{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNoW8DLDPCspXaGZMd379+o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyborgx0x/deepfake_detection/blob/main/ResNext50_and_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "-euq93QXkNOx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms, models"
      ],
      "metadata": {
        "id": "b3O1ukVvkct7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset"
      ],
      "metadata": {
        "id": "rBO55B-mkY27"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "5R3slAzamkWI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "1Yodoi4znWjZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown"
      ],
      "metadata": {
        "id": "k82Sb1k9lGcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/drive/folders/1UX8jXUXyEjhLLZ38tcgOwGsZ6XFSLDJ- -O /content/model --folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R--XpUwylQWb",
        "outputId": "28febf97-3945-40b1-dd9d-455dd0d0f5dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder list\n",
            "Processing file 1Klw2YvgxCMoODEwlY0mpaApJ4Q_mVL6c model_84_acc_10_frames_final_data.pt\n",
            "Processing file 1HqH15cM_Aye4lWLnO4JjMAapgGmOA6Fl model_87_acc_20_frames_final_data.pt\n",
            "Processing file 1kdBOS9eZ1GSRa4kNPkjhQMWKDkBeAdK3 model_89_acc_40_frames_final_data.pt\n",
            "Processing file 1-HU636BQ3g6JOCab9dwcQ3QfHTmHBNtq model_90_acc_20_frames_FF_data.pt\n",
            "Processing file 1nrNmvKTBPc00PvrJDOTDV1Tyh1jtL0Mt model_90_acc_60_frames_final_data.pt\n",
            "Processing file 1PSvjfeNtxwWi3RjK0AnEB6QGMhBiwsYu model_93_acc_100_frames_celeb_FF_data.pt\n",
            "Processing file 1n7XEHfyOh85SGL297KCLtXu0wmLwV9gQ model_95_acc_40_frames_FF_data.pt\n",
            "Processing file 1GQiNcveraGzfhe2kRqgXpwrF8CRdiww5 model_97_acc_60_frames_FF_data.pt\n",
            "Processing file 1SCcLxNSHA1GZHBCDhoFYgWhenlL8_BdU model_97_acc_80_frames_FF_data.pt\n",
            "Processing file 1R4LofQFf93V7pZZ32zAHzDCd07JjdnjZ model_97_acc_100_frames_FF_data.pt\n",
            "Retrieving folder list completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Klw2YvgxCMoODEwlY0mpaApJ4Q_mVL6c\n",
            "To: /content/model/model_84_acc_10_frames_final_data.pt\n",
            "100% 227M/227M [00:02<00:00, 89.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HqH15cM_Aye4lWLnO4JjMAapgGmOA6Fl\n",
            "To: /content/model/model_87_acc_20_frames_final_data.pt\n",
            "100% 227M/227M [00:01<00:00, 149MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kdBOS9eZ1GSRa4kNPkjhQMWKDkBeAdK3\n",
            "To: /content/model/model_89_acc_40_frames_final_data.pt\n",
            "100% 227M/227M [00:02<00:00, 98.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-HU636BQ3g6JOCab9dwcQ3QfHTmHBNtq\n",
            "To: /content/model/model_90_acc_20_frames_FF_data.pt\n",
            "100% 227M/227M [00:02<00:00, 93.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nrNmvKTBPc00PvrJDOTDV1Tyh1jtL0Mt\n",
            "To: /content/model/model_90_acc_60_frames_final_data.pt\n",
            "100% 227M/227M [00:01<00:00, 140MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PSvjfeNtxwWi3RjK0AnEB6QGMhBiwsYu\n",
            "To: /content/model/model_93_acc_100_frames_celeb_FF_data.pt\n",
            "100% 227M/227M [00:02<00:00, 90.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n7XEHfyOh85SGL297KCLtXu0wmLwV9gQ\n",
            "To: /content/model/model_95_acc_40_frames_FF_data.pt\n",
            "100% 227M/227M [00:01<00:00, 181MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GQiNcveraGzfhe2kRqgXpwrF8CRdiww5\n",
            "To: /content/model/model_97_acc_60_frames_FF_data.pt\n",
            "100% 227M/227M [00:01<00:00, 179MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SCcLxNSHA1GZHBCDhoFYgWhenlL8_BdU\n",
            "To: /content/model/model_97_acc_80_frames_FF_data.pt\n",
            "100% 227M/227M [00:01<00:00, 132MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1R4LofQFf93V7pZZ32zAHzDCd07JjdnjZ\n",
            "To: /content/model/model_97_acc_100_frames_FF_data.pt\n",
            "100% 227M/227M [00:01<00:00, 120MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9TgVtu7Xj96O"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes,latent_dim= 2048, lstm_layers=1 , hidden_dim = 2048, bidirectional = False):\n",
        "        super(Model, self).__init__()\n",
        "        model = models.resnext50_32x4d(pretrained = True)\n",
        "        self.model = nn.Sequential(*list(model.children())[:-2])\n",
        "        self.lstm = nn.LSTM(latent_dim,hidden_dim, lstm_layers,  bidirectional)\n",
        "        self.relu = nn.LeakyReLU()\n",
        "        self.dp = nn.Dropout(0.4)\n",
        "        self.linear1 = nn.Linear(2048,num_classes)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size,seq_length, c, h, w = x.shape\n",
        "        x = x.view(batch_size * seq_length, c, h, w)\n",
        "        fmap = self.model(x)\n",
        "        x = self.avgpool(fmap)\n",
        "        x = x.view(batch_size,seq_length,2048)\n",
        "        x_lstm,_ = self.lstm(x,None)\n",
        "        return fmap,self.dp(self.linear1(x_lstm[:,-1,:]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(2).cuda()\n",
        "ACCURACY = 00\n",
        "\n",
        "\n",
        "path_to_model = \"/content/model/model_87_acc_20_frames_final_data.pt\"\n",
        "model.load_state_dict(torch.load(path_to_model))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12aJk9-lmJO",
        "outputId": "03a2006f-5746-411f-b419-6b6b7029262d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lstm): LSTM(2048, 2048, bias=False)\n",
              "  (relu): LeakyReLU(negative_slope=0.01)\n",
              "  (dp): Dropout(p=0.4, inplace=False)\n",
              "  (linear1): Linear(in_features=2048, out_features=2, bias=True)\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_images = []\n",
        "faces_cropped_images = []"
      ],
      "metadata": {
        "id": "2ef01xtInNrA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"/content/john.mp4\")\n",
        "frames = []\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret==True:\n",
        "        frames.append(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "CRbgY7jpnQXF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image as pImage"
      ],
      "metadata": {
        "id": "DBlUWNHsoSDO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length=20\n",
        "for i in range(1, sequence_length+1):\n",
        "    frame = frames[i]\n",
        "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    img = pImage.fromarray(image, 'RGB')\n",
        "    image_name = \"john_preprocessed_\"+str(i)+'.png'\n",
        "    image_path = \"/content/images/\" + image_name\n",
        "    img.save(image_path)\n",
        "    preprocessed_images.append(image_name)"
      ],
      "metadata": {
        "id": "Ae_aUkDtoJxN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao__hvS7rAp2",
        "outputId": "8ea45cf8-02db-48f8-b76b-4558aacb53b0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['john_preprocessed_1.png',\n",
              " 'john_preprocessed_2.png',\n",
              " 'john_preprocessed_3.png',\n",
              " 'john_preprocessed_4.png',\n",
              " 'john_preprocessed_5.png',\n",
              " 'john_preprocessed_6.png',\n",
              " 'john_preprocessed_7.png',\n",
              " 'john_preprocessed_8.png',\n",
              " 'john_preprocessed_9.png',\n",
              " 'john_preprocessed_10.png',\n",
              " 'john_preprocessed_11.png',\n",
              " 'john_preprocessed_12.png',\n",
              " 'john_preprocessed_13.png',\n",
              " 'john_preprocessed_14.png',\n",
              " 'john_preprocessed_15.png',\n",
              " 'john_preprocessed_16.png',\n",
              " 'john_preprocessed_17.png',\n",
              " 'john_preprocessed_18.png',\n",
              " 'john_preprocessed_19.png',\n",
              " 'john_preprocessed_20.png']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face-recognition\n",
        "import face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yAYSajtrL53",
        "outputId": "59e753c0-85b5-4733-807b-656a573f4776"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face-recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face-recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face-recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face-recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face-recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face-recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566171 sha256=315f3311a5d439efc4561f2ef0357788e5645bf68efd00b9f24a2c9b1fd5a5fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "padding = 40\n",
        "faces_found = 0\n",
        "for i in range(1, sequence_length+1):\n",
        "    frame = frames[i]\n",
        "    #fig, ax = plt.subplots(1,1, figsize=(5, 5))\n",
        "    face_locations = face_recognition.face_locations(frame)\n",
        "    if len(face_locations) == 0:\n",
        "        continue\n",
        "    top, right, bottom, left = face_locations[0]\n",
        "    frame_face = frame[top-padding:bottom+padding, left-padding:right+padding]\n",
        "    image = cv2.cvtColor(frame_face, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img = pImage.fromarray(image, 'RGB')\n",
        "    image_name = \"john_cropped_faces_\"+str(i)+'.png'\n",
        "\n",
        "    image_path = \"/content/faces/\" + image_name\n",
        "    img.save(image_path)\n",
        "    faces_found = faces_found + 1\n",
        "    faces_cropped_images.append(image_name)\n"
      ],
      "metadata": {
        "id": "OAcIu5NVrGth"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if faces_found == 0:\n",
        "    print(\"No Face Found\")"
      ],
      "metadata": {
        "id": "0-9tjmXUr_UL"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH=20"
      ],
      "metadata": {
        "id": "iWoUNlNesiz0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "K3eXS35lss7r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class validation_dataset(Dataset):\n",
        "    def __init__(self,video_names,sequence_length=60,transform = None):\n",
        "        self.video_names = video_names\n",
        "        self.transform = transform\n",
        "        self.count = sequence_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_names)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        video_path = self.video_names[idx]\n",
        "        frames = []\n",
        "        a = int(100/self.count)\n",
        "        first_frame = np.random.randint(0,a)\n",
        "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
        "            #if(i % a == first_frame):\n",
        "            faces = face_recognition.face_locations(frame)\n",
        "            try:\n",
        "              top,right,bottom,left = faces[0]\n",
        "              frame = frame[top:bottom,left:right,:]\n",
        "            except:\n",
        "              pass\n",
        "            frames.append(self.transform(frame))\n",
        "            if(len(frames) == self.count):\n",
        "                break\n",
        "        \"\"\"\n",
        "        for i,frame in enumerate(self.frame_extract(video_path)):\n",
        "            if(i % a == first_frame):\n",
        "                frames.append(self.transform(frame))\n",
        "        \"\"\"\n",
        "        # if(len(frames)<self.count):\n",
        "        #   for i in range(self.count-len(frames)):\n",
        "        #         frames.append(self.transform(frame))\n",
        "        #print(\"no of frames\", self.count)\n",
        "        frames = torch.stack(frames)\n",
        "        frames = frames[:self.count]\n",
        "        return frames.unsqueeze(0)\n",
        "\n",
        "    def frame_extract(self,path):\n",
        "      vidObj = cv2.VideoCapture(path)\n",
        "      success = 1\n",
        "      while success:\n",
        "          success, image = vidObj.read()\n",
        "          if success:\n",
        "              yield image"
      ],
      "metadata": {
        "id": "w2RSVdxhsjim"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im_size = 112\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "sm = nn.Softmax()"
      ],
      "metadata": {
        "id": "clCel87StJD_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                                        transforms.ToPILImage(),\n",
        "                                        transforms.Resize((im_size,im_size)),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean,std)])"
      ],
      "metadata": {
        "id": "kNIYPWnFtdYo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_dataset = validation_dataset([\"/content/john.mp4\"], sequence_length=SEQUENCE_LENGTH,transform= train_transforms)"
      ],
      "metadata": {
        "id": "c6gEbGtEse__"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inv_normalize =  transforms.Normalize(mean=-1*np.divide(mean,std),std=np.divide([1,1,1],std))\n"
      ],
      "metadata": {
        "id": "KTAuiHBMtK_s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "sibzjSyatNFT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def im_convert(tensor, video_file_name):\n",
        "    \"\"\" Display a tensor as an image. \"\"\"\n",
        "    image = tensor.to(\"cpu\").clone().detach()\n",
        "    image = image.squeeze()\n",
        "    image = inv_normalize(image)\n",
        "    image = image.numpy()\n",
        "    image = image.transpose(1,2,0)\n",
        "    image = image.clip(0, 1)\n",
        "    # This image is not used\n",
        "    # cv2.imwrite(os.path.join(settings.PROJECT_DIR, 'uploaded_images', video_file_name+'_convert_2.png'),image*255)\n",
        "    return image"
      ],
      "metadata": {
        "id": "GCoGSBVitE6q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def im_plot(tensor):\n",
        "    image = tensor.cpu().numpy().transpose(1,2,0)\n",
        "    b,g,r = cv2.split(image)\n",
        "    image = cv2.merge((r,g,b))\n",
        "    image = image*[0.22803, 0.22145, 0.216989] +  [0.43216, 0.394666, 0.37645]\n",
        "    image = image*255.0\n",
        "    plt.imshow(image.astype(int))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3_WZHEgEtDIE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model,img,path = './', video_file_name=\"\"):\n",
        "  fmap,logits = model(img.to('cuda'))\n",
        "  img = im_convert(img[:,-1,:,:,:], video_file_name)\n",
        "  params = list(model.parameters())\n",
        "  weight_softmax = model.linear1.weight.detach().cpu().numpy()\n",
        "  logits = sm(logits)\n",
        "  _,prediction = torch.max(logits,1)\n",
        "  confidence = logits[:,int(prediction.item())].item()*100\n",
        "  print('confidence of prediction:',logits[:,int(prediction.item())].item()*100)\n",
        "  return [int(prediction.item()),confidence]"
      ],
      "metadata": {
        "id": "JblnMQFetBDl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def plot_heat_map(i, model, img, path = './', video_file_name=''):\n",
        "  fmap,logits = model(img.to('cuda'))\n",
        "  params = list(model.parameters())\n",
        "  weight_softmax = model.linear1.weight.detach().cpu().numpy()\n",
        "  logits = sm(logits)\n",
        "  _,prediction = torch.max(logits,1)\n",
        "  idx = np.argmax(logits.detach().cpu().numpy())\n",
        "  bz, nc, h, w = fmap.shape\n",
        "  #out = np.dot(fmap[-1].detach().cpu().numpy().reshape((nc, h*w)).T,weight_softmax[idx,:].T)\n",
        "  out = np.dot(fmap[i].detach().cpu().numpy().reshape((nc, h*w)).T,weight_softmax[idx,:].T)\n",
        "  predict = out.reshape(h,w)\n",
        "  predict = predict - np.min(predict)\n",
        "  predict_img = predict / np.max(predict)\n",
        "  predict_img = np.uint8(255*predict_img)\n",
        "  out = cv2.resize(predict_img, (im_size,im_size))\n",
        "  heatmap = cv2.applyColorMap(out, cv2.COLORMAP_JET)\n",
        "  img = im_convert(img[:,-1,:,:,:], video_file_name)\n",
        "  result = heatmap * 0.5 + img*0.8*255\n",
        "  # Saving heatmap - Start\n",
        "  heatmap_name = video_file_name+\"_heatmap_\"+str(i)+\".png\"\n",
        "  image_name = os.path.join('/content/heatmap', heatmap_name)\n",
        "  cv2.imwrite(image_name,result)\n",
        "  # Saving heatmap - End\n",
        "  result1 = heatmap * 0.5/255 + img*0.8\n",
        "  r,g,b = cv2.split(result1)\n",
        "  result1 = cv2.merge((r,g,b))\n",
        "  return image_name"
      ],
      "metadata": {
        "id": "8HCTF0hPvVoz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap_images = []\n",
        "sequence_length=20\n",
        "for i in range(0, len([\"/content/john.mp4\"])):\n",
        "    output = \"\"\n",
        "    print(\"<=== | Started Predicition | ===>\")\n",
        "    prediction = predict(model, video_dataset[i], './', \"john\")\n",
        "    confidence = round(prediction[1], 1)\n",
        "    print(\"<=== |  Predicition Done | ===>\")\n",
        "    print(\"<=== | Heat map creation started | ===>\")\n",
        "    for j in range(0, sequence_length):\n",
        "        heatmap_images.append(plot_heat_map(j, model, video_dataset[i], './', \"john\"))\n",
        "    if prediction[0] == 1:\n",
        "        output = \"REAL\"\n",
        "    else:\n",
        "        output = \"FAKE\"\n",
        "    print(\"Prediction : \" , prediction[0],\"==\",output ,\"Confidence : \" , confidence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJCrCSHgsB4w",
        "outputId": "847220af-f740-4178-b10e-bf81916c17b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<=== | Started Predicition | ===>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-c359ec5fe8ad>:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits = sm(logits)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confidence of prediction: 99.68593120574951\n",
            "<=== |  Predicition Done | ===>\n",
            "<=== | Heat map creation started | ===>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heatmap_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDtJNNjKvI9t",
        "outputId": "74b476a0-2ffd-4d23-c045-1906b2cf28f3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/uploaded_images/john_heatmap_0.png',\n",
              " '/content/uploaded_images/john_heatmap_1.png',\n",
              " '/content/uploaded_images/john_heatmap_2.png',\n",
              " '/content/uploaded_images/john_heatmap_3.png',\n",
              " '/content/uploaded_images/john_heatmap_4.png',\n",
              " '/content/uploaded_images/john_heatmap_5.png',\n",
              " '/content/uploaded_images/john_heatmap_6.png',\n",
              " '/content/uploaded_images/john_heatmap_7.png',\n",
              " '/content/uploaded_images/john_heatmap_8.png',\n",
              " '/content/uploaded_images/john_heatmap_9.png',\n",
              " '/content/uploaded_images/john_heatmap_10.png',\n",
              " '/content/uploaded_images/john_heatmap_11.png',\n",
              " '/content/uploaded_images/john_heatmap_12.png',\n",
              " '/content/uploaded_images/john_heatmap_13.png',\n",
              " '/content/uploaded_images/john_heatmap_14.png',\n",
              " '/content/uploaded_images/john_heatmap_15.png',\n",
              " '/content/uploaded_images/john_heatmap_16.png',\n",
              " '/content/uploaded_images/john_heatmap_17.png',\n",
              " '/content/uploaded_images/john_heatmap_18.png',\n",
              " '/content/uploaded_images/john_heatmap_19.png']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}